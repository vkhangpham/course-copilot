"""Runtime entry point for the CourseGen pipeline."""

from __future__ import annotations

import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List

from apps.orchestrator.codeact_registry import build_default_registry
from ccopilot.core.provenance import ProvenanceEvent

from .context import PipelineContext


@dataclass(slots=True)
class PipelineRunArtifacts:
    """Paths generated by the stub pipeline."""

    course_plan: Path
    lecture: Path
    eval_report: Path
    provenance: Path
    manifest: Path
    highlights: Path | None = None
    highlight_source: str | None = None
    use_world_model: bool = True
    teacher_trace: Path | None = None
    notebook_exports: List[Dict[str, Any]] | None = None
    notebook_export_summary: Dict[str, Any] | None = None


def run_pipeline(ctx: PipelineContext, *, dry_run: bool = False) -> PipelineRunArtifacts | None:
    """Execute the pipeline (validate dataset â†’ orchestrator run)."""

    ctx.paths.ensure_directories()

    dataset = _load_dataset(ctx)
    dataset_summary = _summarize_dataset(dataset)
    world_model_store = ctx.config.world_model.sqlite_path
    os.environ["WORLD_MODEL_STORE"] = str(world_model_store)
    snapshot_exists = world_model_store.exists()

    ctx.provenance.log(
        ProvenanceEvent(
            stage="bootstrap",
            message="Pipeline context initialized",
            agent="ccopilot.pipeline",
            payload={
                "repo_root": str(ctx.paths.repo_root),
                "output_dir": str(ctx.paths.output_dir),
                "ablations": ctx.ablations.describe(),
                "dataset_summary": dataset_summary,
                "world_model_store": str(world_model_store),
                "world_model_store_exists": snapshot_exists,
            },
        )
    )

    if ctx.ablations.use_world_model and not snapshot_exists:
        ctx.provenance.log(
            ProvenanceEvent(
                stage="warning",
                message="World-model snapshot missing; run scripts/ingest_handcrafted.py",
                agent="ccopilot.pipeline",
                payload={"expected_path": str(world_model_store)},
            )
        )

    if dry_run:
        ctx.provenance.log(
            ProvenanceEvent(
                stage="dry_run",
                message="Dry run requested; dataset validated without emitting artifacts",
                agent="ccopilot.pipeline",
                payload={"dataset_summary": dataset_summary},
            )
        )
        return None

    from apps.orchestrator import TeacherOrchestrator

    codeact_registry = build_default_registry(dspy_handles=ctx.dspy_handles)
    orchestrator = TeacherOrchestrator(ctx, codeact_registry=codeact_registry)
    orch_artifacts = orchestrator.run_coursegen(
        dataset_summary=dataset_summary,
        world_model_store=world_model_store,
        snapshot_exists=snapshot_exists,
        codeact_registry=codeact_registry,
    )

    ctx.provenance.log(
        ProvenanceEvent(
            stage="artifacts",
            message="Teacher orchestrator generated artifacts",
            agent="ccopilot.pipeline",
            payload={
                "course_plan": str(orch_artifacts.course_plan),
                "lecture": str(orch_artifacts.lecture),
                "eval_report": str(orch_artifacts.eval_report),
                "manifest": str(orch_artifacts.manifest),
                "highlights": str(orch_artifacts.highlights) if orch_artifacts.highlights else None,
            },
        )
    )

    return PipelineRunArtifacts(
        course_plan=orch_artifacts.course_plan,
        lecture=orch_artifacts.lecture,
        eval_report=orch_artifacts.eval_report,
        provenance=orch_artifacts.provenance,
        manifest=orch_artifacts.manifest,
        highlights=orch_artifacts.highlights,
        highlight_source=orch_artifacts.highlight_source,
        use_world_model=ctx.ablations.use_world_model,
        teacher_trace=orch_artifacts.teacher_trace,
        notebook_exports=orch_artifacts.notebook_exports,
        notebook_export_summary=orch_artifacts.notebook_export_summary,
    )


def _load_dataset(ctx: PipelineContext):
    from scripts.handcrafted_loader import load_dataset, validate_dataset  # type: ignore

    dataset = load_dataset(ctx.config.world_model.dataset_dir)
    errors, warnings = validate_dataset(dataset)
    for warning in warnings:
        ctx.provenance.log(
            ProvenanceEvent(
                stage="dataset_warning",
                message=warning,
                agent="ccopilot.pipeline",
            )
        )
    if errors:
        raise RuntimeError(f"Dataset validation failed: {errors}")
    return dataset


def _summarize_dataset(dataset) -> Dict[str, Any]:
    taxonomy = dataset.taxonomy if isinstance(dataset.taxonomy, dict) else {}
    domains: List[str] = []
    for domain in taxonomy.get("domains", []):
        title = domain.get("title") or domain.get("id")
        if title:
            domains.append(title)
        if len(domains) == 3:
            break
    return {
        "concept_count": len(getattr(dataset, "concepts", {})),
        "paper_count": len(getattr(dataset, "papers", [])),
        "timeline_count": len(getattr(dataset, "timeline", [])),
        "quiz_count": len(getattr(dataset, "quiz_bank", [])),
        "top_domains": domains,
    }
