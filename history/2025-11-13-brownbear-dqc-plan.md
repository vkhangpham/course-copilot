# Plan – ccopilot-dqc (Audit orchestrator + CodeAct modules for latent bugs)

## Goal
Document and fix latent reliability issues in the orchestrator + CodeAct stack so the CourseGen PoC can execute the documented pipeline (ablations, world-model access, Notebook export) without hidden failure modes.

## Steps
1. Re-read docs/PLAN.md, docs/PoC.md §§1–4, and the latest history audits to restate the expected behaviors for ablations, CodeAct tool wiring, and Notebook publishing.
2. Static-review `apps/orchestrator/` and `apps/codeact/tools/` for obvious bugs: missing env-variable fallbacks, unchecked exceptions, inverted ablation logic, or skipped persistence hooks.
3. Reproduce suspicious spots via `pytest` (focus: `tests/test_orchestrator_*`, `tests/test_codeact_*`) and targeted CLI invocations (`python apps/orchestrator/run_poc.py ...`). Capture regressions as failing tests.
4. Patch the defects, add coverage, update this plan, bead, and Agent Mail thread; document residual risks if a fix must be deferred.

## Progress
- 2025-11-13 01:32Z – BrownBear registered via Agent Mail, created bead ccopilot-dqc, and broadcasted intent to audit orchestrator + CodeAct stack.
- 2025-11-13 01:42Z – While reviewing the student QA pipeline I noticed `StudentQuizEvaluator._keyword_hits` still performs naive substring checks, so quiz keywords like "acid" match "acidic" and inflate pass rates—flagged for fix + regression test.
- 2025-11-13 01:54Z – Replaced the quiz evaluator’s substring matcher with the same word-boundary regex used by the rubric graders and added a regression test (`tests/test_students.py::test_student_quiz_evaluator_respects_word_boundaries`); `pytest tests/test_students.py -q` now passes (9 tests).
- 2025-11-13 02:05Z – Found that `no_world_model` ablations only tagged `highlight_source="dataset"` when dataset highlights were non-empty, so portal/CLI runs with sparse handcrafted data looked indistinguishable from default runs. Patched `TeacherOrchestrator` to always label dataset-sourced runs and added `tests/test_orchestrator_codeact.py::test_no_world_model_ablation_marks_dataset_source_without_highlights` (alongside rerunning `pytest tests/test_students.py tests/test_orchestrator_codeact.py -q`).
- 2025-11-13 02:20Z – Aligned the legacy placeholder orchestrator (`apps/orchestrator/pipeline.Orchestrator`) with the same highlight-source contract so anyone exercising the stub still emits `highlight_source` in provenance + manifests. Added `tests/test_orchestrator_pipeline_stub.py` to cover both the dataset-only and world-model-enabled paths and ran `pytest tests/test_students.py tests/test_orchestrator_codeact.py tests/test_orchestrator_pipeline_stub.py -q` (19 tests).
- 2025-11-13 02:38Z – Surfaced `highlight_source` in the portal run list API + UI badges so dataset/world-model runs are obvious without drilling into detail views (`apps/portal_backend/main.py`, `frontend/lib/api.ts`, `frontend/components/run-history.tsx`). Backed by updated FastAPI tests (`tests/test_portal_backend.py`) and reran `pytest tests/test_portal_backend.py -q` (11 tests).
- 2025-11-13 02:45Z – Next focus: audit NotebookPublisher/CodeAct export plumbing so offline exports, auto-create skips, and placeholder entries stay consistent across manifests/portal summaries.
- 2025-11-13 02:55Z – Added explicit notebook placeholder records + summaries to the stub orchestrator so manifests produced by docs/examples still report export status (`apps/orchestrator/pipeline.py`, `tests/test_orchestrator_pipeline_stub.py`). Spot check: `pytest tests/test_portal_backend.py tests/test_orchestrator_pipeline_stub.py -q`.
- 2025-11-13 03:05Z – Surfaced notebook export `reason`/`error` details through the portal API + UI and adjusted the dashboard’s counts to ignore skipped entries (`apps/portal_backend/main.py`, `frontend/lib/api.ts`, `frontend/components/run-detail-section.tsx`). Added regression in `tests/test_portal_backend.py::test_notebook_export_reason_exposed` and re-ran `pytest tests/test_portal_backend.py -q` (12 tests).
- 2025-11-13 03:12Z – Ensured offline notebook exports emitted by `push_notebook_section` include a structured `reason="offline_export"`, so manifests/portal entries explain queued states. Updated `_persist_stub_export` + regression (`tests/test_open_notebook_tools.py::test_push_notebook_section_offline_export`), with `pytest tests/test_open_notebook_tools.py -q` green.
- 2025-11-13 04:24Z – BrownStone: fixed both orchestrators so `highlight_source` always records the dataset fallback when the world-model snapshot is missing/empty, plus regression tests for the teacher + stub flows (`apps/orchestrator/teacher.py`, `apps/orchestrator/pipeline.py`, `tests/test_orchestrator_codeact.py`, `tests/test_orchestrator_pipeline_stub.py`). Targeted pytest run covers both suites (12 tests).
- 2025-11-13 04:32Z – BrownStone: `_notebook_skip_reason` now encodes *why* notebook exports are skipped (missing config vs slug), and new test ensures manifests carry the descriptive reason when slugless configs disable exports (`tests/test_orchestrator_codeact.py`). `pytest tests/test_orchestrator_codeact.py -q` remains green.
- 2025-11-13 04:38Z – BrownStone: Hardened the student mutation loop so empty rubric/quiz configs no longer trigger endless retries. `_should_continue` now scales the “two checks” rule based on how many signals are configured (single-check configs still gate properly) and `_grounding_status` defaults to pass only when the rubric omits grounding entirely. Added `tests/test_students.py::test_student_loop_handles_empty_rubrics_and_quiz` and `::test_student_loop_mutates_when_quiz_fails_without_rubrics`; `pytest tests/test_students.py -q` now covers 12 cases.
